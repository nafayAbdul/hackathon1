---
sidebar_position: 6
---

# Chapter 15: Sim-to-Real Transfer Cookbook ‚Äì Making Athena Walk on Real Hardware

## Learning Objectives

By the end of this chapter, you will be able to:
- Implement the ultimate Sim-to-Real recipe: system identification, actuator modeling, latency compensation
- Design domain randomization schedules that work effectively for humanoid robots
- Execute zero-shot transfer of your walking policy from Isaac Sim to real Unitree G1 or Figure 02 class robots
- Complete the final exercise: making "athena" walk 5 meters on real hardware using only the policy trained in simulation

## 15.1 Introduction to Sim-to-Real Transfer

Sim-to-real transfer remains one of the most challenging aspects of robotics, particularly for dynamic systems like humanoid robots. The "reality gap" encompasses differences in dynamics, sensor noise, actuator behavior, contact physics, and environmental conditions between simulation and reality.

For humanoid robots, the gap is especially pronounced due to:
- Complex dynamics with many degrees of freedom
- Underactuated systems requiring balance strategies
- Contact-rich behaviors with challenging ground interaction
- Sensory feedback delays and noise

## 15.2 System Identification for Humanoid Robots

System identification is the process of determining accurate models of the robot's physical properties:

```python
import numpy as np
import scipy.optimize as opt
from scipy.integrate import odeint

class SystemId:
    def __init__(self, robot_name):
        self.robot_name = robot_name
        self.mass_params = {}
        self.inertia_params = {}
        self.friction_params = {}
        
    def identify_mass_parameters(self):
        """Identify actual mass parameters through excitation experiments"""
        # For each link, we'll apply known torques and observe acceleration
        # to identify mass and center of mass
        
        # Simulated data for demonstration
        # In practice, this would come from real experiments
        link_names = ["pelvis", "left_thigh", "right_thigh", "left_shin", "right_shin", 
                      "left_foot", "right_foot", "torso", "left_upper_arm", "right_upper_arm",
                      "left_lower_arm", "right_lower_arm", "left_hand", "right_hand"]
        
        # Mass identification for each link
        for i, link in enumerate(link_names):
            # Apply known torque and measure acceleration
            # Calculate mass from F = ma
            # In simulation, we'll use known values with added noise
            nominal_mass = self.get_nominal_mass(link)
            
            # Add uncertainty to simulate identification errors
            identified_mass = nominal_mass * np.random.uniform(0.95, 1.05)
            
            self.mass_params[link] = identified_mass
        
        return self.mass_params
    
    def get_nominal_mass(self, link_name):
        """Get nominal mass for a given link (from URDF typically)"""
        # This would typically load from URDF
        nominal_masses = {
            "pelvis": 10.0,
            "left_thigh": 5.0,
            "right_thigh": 5.0,
            "left_shin": 3.0,
            "right_shin": 3.0,
            "left_foot": 1.0,
            "right_foot": 1.0,
            "torso": 15.0,
            "left_upper_arm": 2.0,
            "right_upper_arm": 2.0,
            "left_lower_arm": 1.5,
            "right_lower_arm": 1.5,
            "left_hand": 0.5,
            "right_hand": 0.5
        }
        
        return nominal_masses.get(link_name, 1.0)
    
    def identify_friction_parameters(self):
        """Estimate friction properties for joints"""
        # Friction model: tau_f = tau_c + tau_v * velocity + tau_s * sign(velocity)
        joint_names = ["left_hip_yaw", "left_hip_roll", "left_hip_pitch", 
                       "left_knee", "left_ankle_pitch", "left_ankle_roll",
                       "right_hip_yaw", "right_hip_roll", "right_hip_pitch", 
                       "right_knee", "right_ankle_pitch", "right_ankle_roll",
                       "torso_yaw", "torso_roll", "torso_pitch",
                       "left_shoulder_pitch", "left_shoulder_roll", "left_shoulder_yaw",
                       "left_elbow", "left_wrist_pitch", "left_wrist_yaw",
                       "right_shoulder_pitch", "right_shoulder_roll", "right_shoulder_yaw",
                       "right_elbow", "right_wrist_pitch", "right_wrist_yaw"]
        
        for joint in joint_names:
            # Coulomb friction (static)
            coulomb_friction = np.random.uniform(0.1, 0.5)  # Nm
            
            # Viscous friction (velocity dependent)
            viscous_friction = np.random.uniform(0.01, 0.05)  # Nms/rad
            
            # Stribeck friction (signum function factor)
            stribek_friction = np.random.uniform(0.05, 0.2)  # Nm
            
            self.friction_params[joint] = {
                'coulomb': coulomb_friction,
                'viscous': viscous_friction,
                'stribek': stribek_friction
            }
        
        return self.friction_params
    
    def identify_actuator_dynamics(self):
        """Model actuator response characteristics"""
        actuator_params = {}
        
        # For each joint, identify first-order system parameters
        # tau = J * alpha + B * omega + K * (theta_desired - theta_actual)
        # where the actuator has dynamics: H(s) = K / (tau * s + 1)
        
        joint_names = ["left_hip_yaw", "left_hip_roll", "left_hip_pitch", 
                       "left_knee", "left_ankle_pitch", "left_ankle_roll",
                       "right_hip_yaw", "right_hip_roll", "right_hip_pitch", 
                       "right_knee", "right_ankle_pitch", "right_ankle_roll"]
        
        for joint in joint_names:
            # Time constant (tau) in seconds
            time_constant = np.random.uniform(0.005, 0.02)  # 5-20 ms
            
            # Gain (K) - how much torque per command
            gain = np.random.uniform(0.8, 1.2)  # 80-120% of nominal
            
            # Delay (sensor feedback delay)
            delay = np.random.uniform(0.001, 0.005)  # 1-5 ms
            
            actuator_params[joint] = {
                'time_constant': time_constant,
                'gain': gain,
                'delay': delay
            }
        
        return actuator_params

def run_system_identification():
    """Run the complete system identification process"""
    sys_id = SystemId("athena")
    
    print("Starting mass parameter identification...")
    mass_params = sys_id.identify_mass_parameters()
    
    print("Starting friction parameter identification...")
    friction_params = sys_id.identify_friction_parameters()
    
    print("Starting actuator dynamics identification...")
    actuator_params = sys_id.identify_actuator_dynamics()
    
    print("System identification complete!")
    
    return mass_params, friction_params, actuator_params
```

## 15.3 Latency Compensation Techniques

Real hardware has various delays that need compensation:

```python
import numpy as np
from scipy import signal

class LatencyCompensation:
    def __init__(self, dt=0.005):  # 200 Hz control
        self.dt = dt
        self.latency_samples = 4  # 4 control cycles of delay (20ms)
        
        # Store past commands for compensation
        self.command_buffer = np.zeros((self.latency_samples, 23))  # 23 DoF for athena
        self.command_idx = 0
        
        # Initialize state estimation
        self.current_state = np.zeros(47)  # State vector
        
    def add_latency(self, command, measured_delay=0.020):
        """Simulate command latency in the system"""
        # Add to buffer
        self.command_buffer[self.command_idx] = command
        self.command_idx = (self.command_idx + 1) % self.latency_samples
        
        # Return the delayed command
        delayed_idx = (self.command_idx - int(measured_delay / self.dt)) % self.latency_samples
        return self.command_buffer[delayed_idx]
    
    def predictive_control(self, current_state, desired_state):
        """Implement predictive control to compensate for delays"""
        # Simple prediction model: x_future = x_current + dx*dt*latency_samples
        # In practice, this would use a more sophisticated model
        
        # Estimate state derivative
        state_derivative = (current_state - self.current_state) / self.dt
        
        # Predict future state accounting for delay
        predicted_state = current_state + state_derivative * (self.dt * self.latency_samples)
        
        # Compute control based on predicted state
        control_command = self.compute_control(predicted_state, desired_state)
        
        self.current_state = current_state
        return control_command
    
    def compute_control(self, predicted_state, desired_state):
        """Compute control command using predicted state"""
        # This is where your control policy would be applied
        # For the humanoid, this might involve:
        # 1. State estimation (IMU, encoders)
        # 2. Desired trajectory generation
        # 3. Feedback control (PD, MPC, learned policy)
        
        # Placeholder: use the trained policy with predicted state
        error = desired_state - predicted_state
        control_output = np.tanh(error[:23])  # Use first 23 as action space
        
        return control_output
    
    def kalman_filter_estimation(self, measurements, control_input):
        """Use Kalman filter to estimate true state despite delays"""
        # This would implement a Kalman filter for state estimation
        # considering sensor noise and process noise
        
        # Placeholder matrices for Kalman filter
        # In practice, these would be tuned based on system characterization
        F = np.eye(len(self.current_state))  # State transition model
        H = np.eye(len(self.current_state))  # Observation model
        Q = np.eye(len(self.current_state)) * 0.01  # Process noise
        R = np.eye(len(self.current_state)) * 0.1   # Measurement noise
        
        # Kalman filter prediction and update steps
        # (Implementation would be more detailed in practice)
        
        # Return estimated state
        return self.current_state
```

## 15.4 Domain Randomization Schedules

Effective domain randomization requires careful scheduling:

```python
import numpy as np

class DomainRandomizationSchedule:
    def __init__(self):
        # Define the range of each parameter to be randomized
        self.parameters = {
            'mass': {'min': 0.8, 'max': 1.2, 'schedule': 'exponential'},
            'friction': {'min': 0.5, 'max': 1.5, 'schedule': 'linear'},
            'com_offset': {'min': -0.05, 'max': 0.05, 'schedule': 'polynomial'},
            'motor_strength': {'min': 0.9, 'max': 1.1, 'schedule': 'exponential'},
            'sensor_noise': {'min': 0.0, 'max': 0.02, 'schedule': 'linear'},
            'latency': {'min': 0.001, 'max': 0.005, 'schedule': 'linear'}
        }
    
    def get_randomization_schedule(self, progress, max_progress=1.0):
        """
        Get parameter ranges based on training progress
        progress: Current training progress (0.0 to 1.0)
        """
        randomization_ranges = {}
        
        for param_name, param_info in self.parameters.items():
            min_val = param_info['min']
            max_val = param_info['max']
            schedule_type = param_info['schedule']
            
            # Calculate current randomization range based on schedule
            if schedule_type == 'linear':
                # Linearly increase randomization from 0 to full range
                current_range = min_val + (max_val - min_val) * progress
                current_min = 1.0 - (1.0 - min_val) * progress
                current_max = 1.0 + (max_val - 1.0) * progress
                
            elif schedule_type == 'exponential':
                # Exponentially increase randomization (start conservative)
                scale_factor = np.power(progress, 2.0)  # Square for faster ramp-up
                current_range = min_val + (max_val - min_val) * scale_factor
                current_min = 1.0 - (1.0 - min_val) * scale_factor
                current_max = 1.0 + (max_val - 1.0) * scale_factor
                
            elif schedule_type == 'polynomial':
                # Polynomial schedule (e.g., cubic)
                scale_factor = np.power(progress, 3.0)  # Cubic for slower start
                current_range = min_val + (max_val - min_val) * scale_factor
                current_min = 1.0 - (1.0 - min_val) * scale_factor
                current_max = 1.0 + (max_val - 1.0) * scale_factor
            
            randomization_ranges[param_name] = (current_min, current_max)
        
        return randomization_ranges
    
    def apply_randomization(self, sim_env, progress):
        """Apply domain randomization to simulation environment"""
        ranges = self.get_randomization_schedule(progress)
        
        # Apply mass randomization
        mass_min, mass_max = ranges['mass']
        mass_multipliers = np.random.uniform(mass_min, mass_max, size=sim_env.num_envs)
        
        # Apply friction randomization
        friction_min, friction_max = ranges['friction']
        friction_multipliers = np.random.uniform(friction_min, friction_max, size=sim_env.num_envs)
        
        # Apply COM offset randomization
        com_min, com_max = ranges['com_offset']
        com_offsets = np.random.uniform(com_min, com_max, size=(sim_env.num_envs, 3))
        
        # Apply motor strength randomization
        motor_min, motor_max = ranges['motor_strength']
        motor_multipliers = np.random.uniform(motor_min, motor_max, size=(sim_env.num_envs, 23))
        
        # Apply sensor noise randomization
        noise_min, noise_max = ranges['sensor_noise']
        sensor_noise_levels = np.random.uniform(noise_min, noise_max, size=sim_env.num_envs)
        
        # Apply to the simulation environment
        self.set_simulation_parameters(
            sim_env, 
            mass_multipliers, 
            friction_multipliers, 
            com_offsets, 
            motor_multipliers,
            sensor_noise_levels
        )
    
    def set_simulation_parameters(self, sim_env, mass_mult, friction_mult, com_offsets, motor_mult, sensor_noise):
        """Set the randomized parameters in the simulation"""
        # This would interact with the Isaac Sim environment to set parameters
        # Implementation would depend on the specific API
        pass

class AdaptiveRandomization:
    def __init__(self):
        self.success_history = []
        self.param_history = []
        self.adaptation_rate = 0.01
        
    def update_randomization_based_on_performance(self, success_rate, current_params):
        """Adapt randomization parameters based on training performance"""
        self.success_history.append(success_rate)
        self.param_history.append(current_params)
        
        # If success rate is too high (> 95%), increase randomization
        if success_rate > 0.95 and len(self.success_history) > 10:
            # Increase the range of randomization
            for param in current_params:
                current_params[param] = (
                    current_params[param][0] * 0.95,  # Increase range
                    current_params[param][1] * 1.05
                )
        
        # If success rate is too low (< 20%), decrease randomization
        elif success_rate < 0.20 and len(self.success_history) > 10:
            # Decrease the range of randomization
            for param in current_params:
                current_params[param] = (
                    1.0 - (1.0 - current_params[param][0]) * 0.95,  # Decrease range
                    1.0 + (current_params[param][1] - 1.0) * 0.95
                )
        
        return current_params
```

## 15.5 Zero-Shot Transfer Implementation

Implementing zero-shot transfer from simulation to real hardware:

```python
import numpy as np
import onnxruntime as ort
import rospy
from sensor_msgs.msg import JointState
from geometry_msgs.msg import Vector3Stamped
from std_msgs.msg import Float32MultiArray

class ZeroShotTransfer:
    def __init__(self, onnx_model_path):
        # Load the trained ONNX policy
        self.session = ort.InferenceSession(onnx_model_path)
        
        # Initialize ROS node
        rospy.init_node('athena_zero_shot_controller', anonymous=True)
        
        # Subscribe to joint states
        self.joint_state_sub = rospy.Subscriber('/joint_states', JointState, self.joint_state_callback)
        
        # Subscribe to IMU data
        self.imu_sub = rospy.Subscriber('/imu/data', Vector3Stamped, self.imu_callback)
        
        # Publisher for joint commands
        self.joint_cmd_pub = rospy.Publisher('/athena/joint_commands', Float32MultiArray, queue_size=10)
        
        # Internal state
        self.current_joint_positions = np.zeros(23)
        self.current_joint_velocities = np.zeros(23)
        self.imu_data = np.array([0.0, 0.0, 9.81])  # Initialize with gravity
        
        # Latency compensation
        self.latency_comp = LatencyCompensation(dt=0.005)
        
        # Target pose (for walking)
        self.target_pose = np.zeros(23)  # Neutral pose initially
        
    def joint_state_callback(self, msg):
        """Process incoming joint state messages"""
        # Update joint position and velocity arrays
        for i, name in enumerate(self.get_joint_names()):
            if name in msg.name:
                idx = msg.name.index(name)
                if len(msg.position) > idx:
                    self.current_joint_positions[i] = msg.position[idx]
                if len(msg.velocity) > idx:
                    self.current_joint_velocities[i] = msg.velocity[idx]
    
    def imu_callback(self, msg):
        """Process IMU data for balance"""
        self.imu_data = np.array([
            msg.vector.x,
            msg.vector.y,
            msg.vector.z
        ])
    
    def get_joint_names(self):
        """Get the names of joints for the athena humanoid"""
        # This would match the joint names in your robot description
        return [
            "left_hip_yaw", "left_hip_roll", "left_hip_pitch", 
            "left_knee", "left_ankle_pitch", "left_ankle_roll",
            "right_hip_yaw", "right_hip_roll", "right_hip_pitch", 
            "right_knee", "right_ankle_pitch", "right_ankle_roll",
            "torso_yaw", "torso_roll", "torso_pitch",
            "left_shoulder_pitch", "left_shoulder_roll", "left_shoulder_yaw",
            "left_elbow", "left_wrist_pitch", "left_wrist_yaw",
            "right_shoulder_pitch", "right_shoulder_roll", "right_shoulder_yaw",
            "right_elbow", "right_wrist_pitch", "right_wrist_yaw"
        ][:23]  # Only first 23 joints for this example
    
    def prepare_observation(self):
        """Prepare observation vector from sensor data"""
        # Create observation vector from joint positions, velocities, and IMU
        obs = np.concatenate([
            self.current_joint_positions,  # Joint positions
            self.current_joint_velocities,  # Joint velocities
            self.imu_data,  # IMU data (acceleration)
            [0.0] * 11  # Additional state information (computation can be added)
        ])
        
        return obs
    
    def compute_action(self, observation):
        """Get action from the trained policy"""
        # Reshape observation to batch size of 1
        obs_input = observation.reshape(1, -1).astype(np.float32)
        
        # Run inference
        input_name = self.session.get_inputs()[0].name
        output = self.session.run(None, {input_name: obs_input})
        
        # Get action from output (assuming first output is action)
        action = output[0][0]  # Remove batch dimension
        
        return action
    
    def run_control_loop(self):
        """Main control loop for the humanoid"""
        rate = rospy.Rate(200)  # 200 Hz control loop
        
        while not rospy.is_shutdown():
            # Prepare observation
            obs = self.prepare_observation()
            
            # Get action from policy
            action = self.compute_action(obs)
            
            # Apply latency compensation
            compensated_action = self.latency_comp.predictive_control(obs, action)
            
            # Publish joint commands
            cmd_msg = Float32MultiArray()
            cmd_msg.data = [float(val) for val in compensated_action]
            self.joint_cmd_pub.publish(cmd_msg)
            
            rate.sleep()
    
    def execute_5m_walk(self):
        """Execute the final exercise: 5m walk"""
        print("Starting 5m walk exercise...")
        
        # Initialize walking controller
        self.target_pose = self.get_walking_target()  # Set initial walking target
        
        # Run for specific duration (or until 5m is achieved)
        start_time = rospy.Time.now()
        max_duration = rospy.Duration(60)  # 60 seconds maximum
        
        rate = rospy.Rate(200)
        while (rospy.Time.now() - start_time) < max_duration and not rospy.is_shutdown():
            # Main control loop (as implemented above)
            obs = self.prepare_observation()
            action = self.compute_action(obs)
            compensated_action = self.latency_comp.predictive_control(obs, action)
            
            cmd_msg = Float32MultiArray()
            cmd_msg.data = [float(val) for val in compensated_action]
            self.joint_cmd_pub.publish(cmd_msg)
            
            # Check if goal reached (simplified check)
            # In practice, this would involve position tracking
            if self.check_5m_walk_complete():
                print("Successfully walked 5 meters!")
                break
            
            rate.sleep()
        
        print("5m walk exercise completed or timed out.")

    def get_walking_target(self):
        """Set target for walking behavior"""
        # This would set a consistent walking pattern
        neutral = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0,  # Left leg
                           0.0, 0.0, 0.0, 0.0, 0.0, 0.0,  # Right leg
                           0.0, 0.0, 0.0,  # Torso
                           0.0, 0.0, 0.0, 0.0, 0.0, 0.0,  # Left arm
                           0.0, 0.0, 0.0, 0.0, 0.0, 0.0])  # Right arm
        
        # Add slight walking biases
        walking_bias = np.array([0.0, 0.0, 0.05, 0.1, 0.0, 0.0,  # Left leg (forward)
                                0.0, 0.0, 0.05, 0.1, 0.0, 0.0,   # Right leg
                                0.0, 0.0, 0.0,   # Torso (upright)
                                0.0, 0.0, 0.0, 0.0, 0.0, 0.0,  # Left arm
                                0.0, 0.0, 0.0, 0.0, 0.0, 0.0])  # Right arm
        
        return neutral + walking_bias
    
    def check_5m_walk_complete(self):
        """Check if the robot has walked 5 meters forward"""
        # This would require position tracking (from motion capture, VSLAM, or odometry)
        # For simulation, we can just return False to continue
        return False  # Placeholder - implement actual tracking

def main():
    # Initialize zero-shot transfer controller
    controller = ZeroShotTransfer("outputs/athena_walking_policy.onnx")
    
    print("Zero-shot transfer controller initialized.")
    print("Starting control loop...")
    
    try:
        # Run the 5m walk exercise
        controller.execute_5m_walk()
    except KeyboardInterrupt:
        print("Control interrupted by user")
    finally:
        print("Controller shutting down.")

if __name__ == "__main__":
    main()
```

## 15.6 Complete Integration: The Ultimate "isaacsim.run" Command

Let's create the legendary one-liner command that launches the complete autonomous humanoid:

```bash
#!/bin/bash
# isaacsim.run - The legendary one-liner to launch the full autonomous humanoid

# This script launches a complete pipeline:
# 1. Starts Isaac Sim with photorealistic "athena" humanoid
# 2. Initializes Isaac ROS 2 perception stack
# 3. Loads trained walking policy
# 4. Begins autonomous operation in apartment environment

echo "üöÄ Launching Athena autonomous humanoid system..."

# Check prerequisites
if [ ! command -v python3 &> /dev/null ]; then
    echo "‚ùå Python3 is required but not installed."
    exit 1
fi

if [ ! command -v docker &> /dev/null ]; then
    echo "‚ö†Ô∏è  Docker is recommended for Isaac ROS 2 components"
fi

# Set up environment variables
export ISAACSIM_PATH="${ISAACSIM_PATH:-/isaac-sim}"
export ISAAC_ROS_WS="${ISAAC_ROS_WS:-/opt/isaac-ros-dev}"
export CUDA_VISIBLE_DEVICES=0

# Launch Isaac Sim with the "athena" humanoid in photorealistic apartment
echo "üîß Starting Isaac Sim 2025.2 with Athena humanoid..."
nohup python3 -m omni.isaac.sim.python.gym --no-window --num_envs 1 \
  --headless --summary-path /tmp/isaac_sim_summary.json \
  --config "athena_apartment_config.yaml" &>/tmp/isaac_sim.log &

ISAACSIM_PID=$!

# Wait for Isaac Sim to initialize
sleep 10

# Launch Isaac ROS 2 perception stack
echo "üëÅÔ∏è Starting Isaac ROS 2 perception stack..."
source /opt/ros/humble/setup.bash
source $ISAAC_ROS_WS/install/setup.bash

ros2 launch athena_perception athena_perception.launch.py &>/tmp/isaac_ros.log &
ROS_PID=$!

# Launch trained policy controller
echo "ü§ñ Starting trained policy controller..."
source $ISAAC_ROS_WS/install/setup.bash
python3 -m athena_policy_controller \
  --policy-path /models/athena_walking_policy.onnx \
  --control-freq 200 \
  --sensor-fusion &>/tmp/policy_controller.log &
CTRL_PID=$!

# Launch navigation stack
echo "üß≠ Starting navigation stack..."
ros2 launch athena_nav2 athena_nav2.launch.py &>/tmp/nav2.log &
NAV_PID=$!

# Print success message with PIDs
echo "‚úÖ Athena autonomous system is now running!"
echo "üìä Process IDs:"
echo "   Isaac Sim: $ISAACSIM_PID"
echo "   ROS Stack: $ROS_PID"
echo "   Controller: $CTRL_PID"
echo "   Navigation: $NAV_PID"
echo ""
echo "üîç Check logs at /tmp/*.log for details"
echo "üö™ The autonomous humanoid is now operational in the photorealistic apartment!"
```

## 15.7 Chapter Summary

In this final chapter, we've covered the complete sim-to-real transfer process for the "athena" humanoid robot. We implemented system identification to characterize real-world parameters, applied latency compensation techniques, designed effective domain randomization schedules, and executed zero-shot transfer of our trained policy to real hardware. The culmination of this work is the legendary "isaacsim.run" one-liner that launches the complete autonomous humanoid system.

## End-of-Chapter Exercises

1. Perform system identification on your physical humanoid robot (or simulate it)
2. Implement latency compensation for your robot's control system
3. Design and test domain randomization schedules that improve sim-to-real transfer
4. Execute the final challenge: make your "athena" robot walk 5 meters using only the policy trained in simulation

## Module 3 Summary

Module 3 has provided you with comprehensive knowledge of NVIDIA's Isaac Platform for creating advanced AI-robot brain systems. You've learned to:

1. Install and configure Isaac Sim 2025.2 with optimal performance
2. Convert URDF models to USD with complete articulation and materials
3. Implement Isaac ROS 2 perception stack with hardware acceleration
4. Integrate Nav2 and MoveIt 2 for complete navigation and manipulation
5. Train walking policies using Isaac Lab 1.3 and rsl-rl
6. Execute sim-to-real transfer with domain randomization and latency compensation

This module completes the foundational knowledge needed to build sophisticated AI-robot systems with NVIDIA's Isaac platform. The skills learned here form the core of modern embodied AI systems for humanoid robotics.

The companion code and assets for this module are available in the `github.com/yourname/physical-ai-book/tree/main/module3` repository, including all USD assets, training scripts, and configuration files needed to reproduce the examples in this module.

With Module 3 complete, you now have a comprehensive understanding of creating AI-robot brains using NVIDIA's Isaac Platform. The next module will explore vision-language-action integration, building on the foundation you've established with Isaac and the "athena" humanoid robot.

## 15.7 Chapter Summary

In this final chapter, we've covered the complete sim-to-real transfer process for the "athena" humanoid robot. We implemented system identification to characterize real-world parameters, applied latency compensation techniques, designed effective domain randomization schedules, and executed zero-shot transfer of our trained policy to real hardware. The culmination of this work is the legendary "isaacsim.run" one-liner that launches the complete autonomous humanoid system.

## End-of-Chapter Exercises

1. Perform system identification on your physical humanoid robot (or simulate it)
2. Implement latency compensation for your robot's control system
3. Design and test domain randomization schedules that improve sim-to-real transfer
4. Execute the final challenge: make your "athena" robot walk 5 meters using only the policy trained in simulation

## Module 3 Summary

Module 3 has provided you with comprehensive knowledge of NVIDIA's Isaac Platform for creating advanced AI-robot brain systems. You've learned to:

1. Install and configure Isaac Sim 2025.2 with optimal performance
2. Convert URDF models to USD with complete articulation and materials
3. Implement Isaac ROS 2 perception stack with hardware acceleration
4. Integrate Nav2 and MoveIt 2 for complete navigation and manipulation
5. Train walking policies using Isaac Lab 1.3 and rsl-rl
6. Execute sim-to-real transfer with domain randomization and latency compensation

This module completes the foundational knowledge needed to build sophisticated AI-robot systems with NVIDIA's Isaac platform. The skills learned here form the core of modern embodied AI systems for humanoid robotics.

The companion code and assets for this module are available in the `github.com/yourname/physical-ai-book/tree/main/module3` repository, including all USD assets, training scripts, and configuration files needed to reproduce the examples in this module.

With Module 3 complete, you now have a comprehensive understanding of creating AI-robot brains using NVIDIA's Isaac Platform. The next module will explore vision-language-action integration, building on the foundation you've established with Isaac and the "athena" humanoid robot.